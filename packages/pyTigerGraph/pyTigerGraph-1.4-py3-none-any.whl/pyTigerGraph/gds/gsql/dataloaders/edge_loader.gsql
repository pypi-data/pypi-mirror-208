CREATE QUERY edge_loader_{QUERYSUFFIX}(
    INT num_batches=1, 
    BOOL shuffle=FALSE,
    STRING filter_by,
    SET<STRING> e_types,
    STRING delimiter,
    STRING kafka_address="",
    STRING kafka_topic,
    INT kafka_topic_partitions=1,
    STRING kafka_max_size="104857600",
    INT kafka_timeout=300000,
    STRING security_protocol="",
    STRING sasl_mechanism="",
    STRING sasl_username="",
    STRING sasl_password="",
    STRING ssl_ca_location="",
    STRING ssl_certificate_location="",
    STRING ssl_key_location="",
    STRING ssl_key_password="",
    STRING ssl_endpoint_identification_algorithm="",
    STRING sasl_kerberos_service_name="",
    STRING sasl_kerberos_keytab="",
    STRING sasl_kerberos_principal=""
) SYNTAX V1 { 
    /*
    This query generates batches of edges.

    Parameters :
      num_batches    : Number of batches to divide the edges.
      shuffle        : Whether to shuffle edges before collecting data.
      filter_by      : A Boolean attribute to determine which edges are included.
      e_types        : Edge types to be included.
      kafka_address  : Address of the Kafka cluster to send data to.
      kafka_topic    : The Kafka topic to send data to.
      kafka_topic_partitions: Number of partitions for the given Kafka topic.
      kafka_max_size : Maximum Kafka message size.
      security_protocol : Security prototol for Kafka.
      sasl_mechanism : Authentication mechanism for Kafka.
      sasl_username  : SASL username for Kafka. 
      sasl_password  : SASL password for Kafka. 
      ssl_ca_location: Path to CA certificate for verifying the Kafka broker key
    */
    INT num_vertices;
    INT kafka_errcode;
    SumAccum<INT> @tmp_id;
    SumAccum<STRING> @@kafka_error;
    UINT producer;

    # Initialize Kafka producer
    IF kafka_address != "" THEN
        producer = init_kafka_producer(
            kafka_address, kafka_max_size, security_protocol, 
            sasl_mechanism, sasl_username, sasl_password, ssl_ca_location,
            ssl_certificate_location, ssl_key_location, ssl_key_password,
            ssl_endpoint_identification_algorithm, sasl_kerberos_service_name,
            sasl_kerberos_keytab, sasl_kerberos_principal);
    END;

    # Shuffle vertex ID if needed
    start = {ANY};
    IF shuffle THEN
        num_vertices = start.size();
        res = SELECT s 
              FROM start:s
              POST-ACCUM s.@tmp_id = floor(rand()*num_vertices);
    ELSE
        res = SELECT s 
              FROM start:s
              POST-ACCUM s.@tmp_id = getvid(s);
    END;

    # Generate batches
    FOREACH batch_id IN RANGE[0, num_batches-1] DO
        SumAccum<STRING> @@e_batch;
        start = {ANY};
        IF filter_by IS NOT NULL THEN
            res = 
                SELECT s
                FROM start:s -(e_types:e)- :t
                WHERE e.getAttr(filter_by, "BOOL") and ((s.@tmp_id+t.@tmp_id)*(s.@tmp_id+t.@tmp_id+1)/2+t.@tmp_id)%num_batches==batch_id
                ACCUM 
                    {EDGEATTRS}; 
        ELSE
            res = 
                SELECT s
                FROM start:s -(e_types:e)- :t
                WHERE ((s.@tmp_id+t.@tmp_id)*(s.@tmp_id+t.@tmp_id+1)/2+t.@tmp_id)%num_batches==batch_id
                ACCUM 
                    {EDGEATTRS};
        END;
        # Export batch
        IF kafka_address != "" THEN
            # Write to kafka
            kafka_errcode = write_to_kafka(producer, kafka_topic, batch_id%kafka_topic_partitions, "edge_batch_" + stringify(batch_id), @@e_batch);
            IF kafka_errcode != 0 THEN 
                @@kafka_error += ("Error sending edge batch " + stringify(batch_id) + ": "+ stringify(kafka_errcode) + "\n");
            END;
        ELSE
            # Add to response
            PRINT @@e_batch AS edge_batch;
        END;
    END; 
    IF kafka_address != "" THEN
        kafka_errcode = close_kafka_producer(producer, kafka_timeout);
        IF kafka_errcode != 0 THEN 
            @@kafka_error += ("Error shutting down Kafka producer: " + stringify(kafka_errcode) + "\n");
        END;
        PRINT @@kafka_error as kafkaError;
    END;
}